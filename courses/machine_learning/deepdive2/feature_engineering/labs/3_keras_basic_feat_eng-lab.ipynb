{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNdWfPXCjTjY"
   },
   "source": [
    "# Performing Basic Feature Engineering in Keras \n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "\n",
    "1. Create an input pipeline using tf.data.\n",
    "2. Engineer features to create categorical, crossed, and numerical feature columns.\n",
    "\n",
    "\n",
    "## Introduction \n",
    "In this lab, we utilize feature engineering to improve the prediction of housing prices using a Keras Sequential Model.\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in the notebook where you will complete the notebook cell's code before running. Refer to the [solution](../solutions/3_keras_basic_feat_eng.ipynb) for reference. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VxyBFc_kKazA"
   },
   "source": [
    "Start by importing the necessary libraries for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/osboxes/anaconda3/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/osboxes/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/osboxes/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/osboxes/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/osboxes/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "# Install Sklearn\n",
    "!python3 -m pip install --user scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhq5zEbGg0XX"
   },
   "source": [
    "### Restart the kernel\n",
    "\n",
    "After you install the packages, you need to restart the notebook kernel so that it can find the packages. (Click **Kernel > Restart Kernel > Restart**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9dEreb4QKizj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.16.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow.keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column as fc\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import plot_model\n",
    "\n",
    "print(\"TensorFlow version: \",tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the Google Machine Learning Courses Programming Exercises use the  [California Housing Dataset](https://developers.google.com/machine-learning/crash-course/california-housing-data-description\n",
    "), which contains data drawn from the 1990 U.S. Census.  Our lab dataset has been pre-processed so that there are no missing values.\n",
    "\n",
    "First, let's download the raw .csv data by copying the data from a cloud storage bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not os.path.isdir(\"../data\"):\n",
    "#    os.makedirs(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gsutil cp gs://cloud-training/mlongcp/v3.0_MLonGC/toy_data/housing_pre-proc_toy.csv ../data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1068\n",
      "-rw-rw-r-- 1 osboxes osboxes 142150 Jun 29 13:09 housing_pre-proc_toy.csv\n",
      "-rw-rw-r-- 1 osboxes osboxes 141449 Jun 11 21:23 traffic-taxi-test.csv\n",
      "-rw-rw-r-- 1 osboxes osboxes 662312 Jun 11 21:23 traffic-taxi-train.csv\n",
      "-rw-rw-r-- 1 osboxes osboxes 141062 Jun 11 21:23 traffic-taxi-valid.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../../../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lM6-n6xntv3t"
   },
   "source": [
    "Now, let's read in the dataset just copied from the cloud storage bucket and create a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "REZ57BXCLdfG",
    "outputId": "a6ef2eda-c7eb-4e2d-92e4-e7fcaa20b0af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41</td>\n",
       "      <td>880</td>\n",
       "      <td>129</td>\n",
       "      <td>322</td>\n",
       "      <td>126</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21</td>\n",
       "      <td>7099</td>\n",
       "      <td>1106</td>\n",
       "      <td>2401</td>\n",
       "      <td>1138</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1467</td>\n",
       "      <td>190</td>\n",
       "      <td>496</td>\n",
       "      <td>177</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1274</td>\n",
       "      <td>235</td>\n",
       "      <td>558</td>\n",
       "      <td>219</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1627</td>\n",
       "      <td>280</td>\n",
       "      <td>565</td>\n",
       "      <td>259</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                  41          880             129   \n",
       "1    -122.22     37.86                  21         7099            1106   \n",
       "2    -122.24     37.85                  52         1467             190   \n",
       "3    -122.25     37.85                  52         1274             235   \n",
       "4    -122.25     37.85                  52         1627             280   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0         322         126         8.3252              452600        NEAR BAY  \n",
       "1        2401        1138         8.3014              358500        NEAR BAY  \n",
       "2         496         177         7.2574              352100        NEAR BAY  \n",
       "3         558         219         5.6431              341300        NEAR BAY  \n",
       "4         565         259         3.8462              342200        NEAR BAY  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.read_csv('../../../data/housing_pre-proc_toy.csv', on_bad_lines='skip')\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use .describe() to see some summary statistics for the numeric fields in our dataframe. Note, for example, the count row and corresponding columns. The count shows 2500.000000 for all feature columns. Thus, there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-121.501836</td>\n",
       "      <td>37.802288</td>\n",
       "      <td>30.088400</td>\n",
       "      <td>2522.734000</td>\n",
       "      <td>491.862400</td>\n",
       "      <td>1246.225200</td>\n",
       "      <td>458.122000</td>\n",
       "      <td>3.694312</td>\n",
       "      <td>170288.731200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.015963</td>\n",
       "      <td>0.803090</td>\n",
       "      <td>13.878416</td>\n",
       "      <td>1988.411988</td>\n",
       "      <td>362.499497</td>\n",
       "      <td>925.075463</td>\n",
       "      <td>341.744308</td>\n",
       "      <td>1.859422</td>\n",
       "      <td>97550.278529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.300000</td>\n",
       "      <td>36.130000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>22500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-122.200000</td>\n",
       "      <td>37.600000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1420.750000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>2.357875</td>\n",
       "      <td>92950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-122.030000</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2052.000000</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>1030.500000</td>\n",
       "      <td>374.500000</td>\n",
       "      <td>3.262200</td>\n",
       "      <td>150800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-120.697500</td>\n",
       "      <td>37.960000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3007.250000</td>\n",
       "      <td>581.250000</td>\n",
       "      <td>1488.250000</td>\n",
       "      <td>538.000000</td>\n",
       "      <td>4.662975</td>\n",
       "      <td>219650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-118.910000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>28258.000000</td>\n",
       "      <td>3864.000000</td>\n",
       "      <td>12203.000000</td>\n",
       "      <td>3701.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         longitude     latitude  housing_median_age   total_rooms  \\\n",
       "count  2500.000000  2500.000000         2500.000000   2500.000000   \n",
       "mean   -121.501836    37.802288           30.088400   2522.734000   \n",
       "std       1.015963     0.803090           13.878416   1988.411988   \n",
       "min    -124.300000    36.130000            2.000000     12.000000   \n",
       "25%    -122.200000    37.600000           18.000000   1420.750000   \n",
       "50%    -122.030000    37.800000           30.000000   2052.000000   \n",
       "75%    -120.697500    37.960000           41.000000   3007.250000   \n",
       "max    -118.910000    41.950000           52.000000  28258.000000   \n",
       "\n",
       "       total_bedrooms    population   households  median_income  \\\n",
       "count     2500.000000   2500.000000  2500.000000    2500.000000   \n",
       "mean       491.862400   1246.225200   458.122000       3.694312   \n",
       "std        362.499497    925.075463   341.744308       1.859422   \n",
       "min          4.000000     18.000000     2.000000       0.499900   \n",
       "25%        282.000000    718.000000   263.000000       2.357875   \n",
       "50%        402.000000   1030.500000   374.500000       3.262200   \n",
       "75%        581.250000   1488.250000   538.000000       4.662975   \n",
       "max       3864.000000  12203.000000  3701.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count         2500.000000  \n",
       "mean        170288.731200  \n",
       "std          97550.278529  \n",
       "min          22500.000000  \n",
       "25%          92950.000000  \n",
       "50%         150800.000000  \n",
       "75%         219650.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0zhLtQqMPem"
   },
   "source": [
    "####  Split the dataset for ML\n",
    "\n",
    "The dataset we loaded was a single CSV file. We will split this into train, validation, and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "YEOpw7LhMYsI",
    "outputId": "6161a660-7133-465a-d754-d7acae2b68c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 train examples\n",
      "400 validation examples\n",
      "500 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(housing_df, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dz9kfjOMBX9U"
   },
   "source": [
    "Now, we need to output the split files.  We will specifically need the test.csv later for testing.  You should see the files appear in the home directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "ADX23QUu_Wiu",
    "outputId": "e97fa59e-4ed4-48a3-8fba-c95f293944ee"
   },
   "outputs": [],
   "source": [
    "train.to_csv('../../../data/housing-train.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.to_csv('../../../data/housing-val.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "CU1FgmKEAmWh",
    "outputId": "2cce91e1-2c4a-4fe8-a6c3-3da52cb9458f"
   },
   "outputs": [],
   "source": [
    "test.to_csv('../../../data/housing-test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             0\n",
       "latitude              0\n",
       "housing_median_age    0\n",
       "total_rooms           0\n",
       "total_bedrooms        0\n",
       "population            0\n",
       "households            0\n",
       "median_income         0\n",
       "median_house_value    0\n",
       "ocean_proximity       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ../../../data/housing_pre-proc_toy.csv <==\n",
      "longitude,latitude,housing_median_age,total_rooms,total_bedrooms,population,households,median_income,median_house_value,ocean_proximity\n",
      "-122.23,37.88,41,880,129,322,126,8.3252,452600,NEAR BAY\n",
      "-122.22,37.86,21,7099,1106,2401,1138,8.3014,358500,NEAR BAY\n",
      "-122.24,37.85,52,1467,190,496,177,7.2574,352100,NEAR BAY\n",
      "-122.25,37.85,52,1274,235,558,219,5.6431,341300,NEAR BAY\n",
      "-122.25,37.85,52,1627,280,565,259,3.8462,342200,NEAR BAY\n",
      "-122.25,37.85,52,919,213,413,193,4.0368,269700,NEAR BAY\n",
      "-122.25,37.84,52,2535,489,1094,514,3.6591,299200,NEAR BAY\n",
      "-122.25,37.84,52,3104,687,1157,647,3.12,241400,NEAR BAY\n",
      "-122.26,37.84,42,2555,665,1206,595,2.0804,226700,NEAR BAY\n",
      "\n",
      "==> ../../../data/housing-test.csv <==\n",
      "longitude,latitude,housing_median_age,total_rooms,total_bedrooms,population,households,median_income,median_house_value,ocean_proximity\n",
      "-122.23,37.79,48,1696,396,1481,343,2.0375,122500,NEAR BAY\n",
      "-122.07,37.69,29,2304,618,1021,552,2.5362,203800,NEAR BAY\n",
      "-119.7,36.81,32,2623,528,1570,492,2.7159,68000,INLAND\n",
      "-122.27,37.82,43,1007,312,558,253,1.7348,137500,NEAR BAY\n",
      "-120.55,38.12,10,1566,325,785,291,2.5,116100,INLAND\n",
      "-122.27,37.85,50,1279,300,675,255,1.9028,150800,NEAR BAY\n",
      "-121.84,39.73,52,857,232,520,198,0.987,112500,INLAND\n",
      "-122.24,37.8,52,888,168,360,175,2.1944,211500,NEAR BAY\n",
      "-122.0,37.99,28,4035,641,1881,659,5.4607,192300,INLAND\n",
      "\n",
      "==> ../../../data/housing-train.csv <==\n",
      "longitude,latitude,housing_median_age,total_rooms,total_bedrooms,population,households,median_income,median_house_value,ocean_proximity\n",
      "-122.08,37.99,19,4657,739,1914,732,5.0509,199900,NEAR BAY\n",
      "-120.63,38.73,11,4577,836,1944,700,4.0675,140200,INLAND\n",
      "-119.74,36.77,30,2427,482,1375,518,2.5737,76900,INLAND\n",
      "-119.92,38.91,15,3831,625,984,328,5.0718,162500,INLAND\n",
      "-122.08,37.72,31,3866,531,1368,521,6.187,340400,NEAR BAY\n",
      "-119.56,36.7,40,1195,326,1135,315,2.1182,58900,INLAND\n",
      "-121.52,39.51,30,3085,610,1688,575,2.334,72200,INLAND\n",
      "-121.72,37.98,5,7105,1143,3523,1088,5.0468,168800,INLAND\n",
      "-119.69,36.79,5,2613,476,1490,481,4.0993,83000,INLAND\n",
      "\n",
      "==> ../../../data/housing-val.csv <==\n",
      "longitude,latitude,housing_median_age,total_rooms,total_bedrooms,population,households,median_income,median_house_value,ocean_proximity\n",
      "-119.78,36.77,45,1315,256,666,240,2.3562,58100,INLAND\n",
      "-122.13,37.67,38,2012,347,880,332,3.1734,181600,NEAR BAY\n",
      "-120.54,38.75,9,3006,540,1102,418,3.9812,136600,INLAND\n",
      "-122.27,38.04,47,1685,405,835,372,2.3103,134500,NEAR BAY\n",
      "-122.24,37.83,52,2449,312,916,316,8.1194,471600,NEAR BAY\n",
      "-122.21,37.81,52,1389,212,510,224,5.2402,296400,NEAR BAY\n",
      "-122.23,37.8,52,1252,299,844,280,2.3929,111900,NEAR BAY\n",
      "-122.31,38.01,18,4123,874,1895,772,3.2759,195000,NEAR BAY\n",
      "-119.72,36.72,15,1713,246,766,232,6.8162,127200,INLAND\n"
     ]
    }
   ],
   "source": [
    "!head ../../../data/housing*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aj35eYy_lutI"
   },
   "source": [
    "## Lab Task 1: Create an input pipeline using tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84ef46LXMfvu"
   },
   "source": [
    "Next, we will wrap the dataframes with [tf.data](https://www.tensorflow.org/guide/datasets). This will enable us  to use feature columns as a bridge to map from the columns in the Pandas dataframe to features used to train the model. \n",
    "\n",
    "Here, we create an input pipeline using tf.data.  This function is missing two lines.  Correct and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe type :<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'longitude': 0      -122.23\n",
       "  1      -122.22\n",
       "  2      -122.24\n",
       "  3      -122.25\n",
       "  4      -122.25\n",
       "           ...  \n",
       "  2495   -122.16\n",
       "  2496   -122.19\n",
       "  2497   -122.25\n",
       "  2498   -122.16\n",
       "  2499   -122.13\n",
       "  Name: longitude, Length: 2500, dtype: float64,\n",
       "  'latitude': 0       37.88\n",
       "  1       37.86\n",
       "  2       37.85\n",
       "  3       37.85\n",
       "  4       37.85\n",
       "          ...  \n",
       "  2495    39.74\n",
       "  2496    39.74\n",
       "  2497    39.79\n",
       "  2498    39.78\n",
       "  2499    39.74\n",
       "  Name: latitude, Length: 2500, dtype: float64,\n",
       "  'housing_median_age': 0       41\n",
       "  1       21\n",
       "  2       52\n",
       "  3       52\n",
       "  4       52\n",
       "          ..\n",
       "  2495    20\n",
       "  2496    39\n",
       "  2497    16\n",
       "  2498    32\n",
       "  2499    20\n",
       "  Name: housing_median_age, Length: 2500, dtype: int64,\n",
       "  'total_rooms': 0        880\n",
       "  1       7099\n",
       "  2       1467\n",
       "  3       1274\n",
       "  4       1627\n",
       "          ... \n",
       "  2495     707\n",
       "  2496    4179\n",
       "  2497    2127\n",
       "  2498    1288\n",
       "  2499    1401\n",
       "  Name: total_rooms, Length: 2500, dtype: int64,\n",
       "  'total_bedrooms': 0        129\n",
       "  1       1106\n",
       "  2        190\n",
       "  3        235\n",
       "  4        280\n",
       "          ... \n",
       "  2495     126\n",
       "  2496     814\n",
       "  2497     412\n",
       "  2498     221\n",
       "  2499     280\n",
       "  Name: total_bedrooms, Length: 2500, dtype: int64,\n",
       "  'population': 0        322\n",
       "  1       2401\n",
       "  2        496\n",
       "  3        558\n",
       "  4        565\n",
       "          ... \n",
       "  2495     337\n",
       "  2496    2111\n",
       "  2497    1104\n",
       "  2498     562\n",
       "  2499     668\n",
       "  Name: population, Length: 2500, dtype: int64,\n",
       "  'households': 0        126\n",
       "  1       1138\n",
       "  2        177\n",
       "  3        219\n",
       "  4        259\n",
       "          ... \n",
       "  2495     125\n",
       "  2496     809\n",
       "  2497     369\n",
       "  2498     203\n",
       "  2499     250\n",
       "  Name: households, Length: 2500, dtype: int64,\n",
       "  'median_income': 0       8.3252\n",
       "  1       8.3014\n",
       "  2       7.2574\n",
       "  3       5.6431\n",
       "  4       3.8462\n",
       "           ...  \n",
       "  2495    3.0469\n",
       "  2496    2.3507\n",
       "  2497    3.0469\n",
       "  2498    2.3250\n",
       "  2499    2.2569\n",
       "  Name: median_income, Length: 2500, dtype: float64,\n",
       "  'ocean_proximity': 0       NEAR BAY\n",
       "  1       NEAR BAY\n",
       "  2       NEAR BAY\n",
       "  3       NEAR BAY\n",
       "  4       NEAR BAY\n",
       "            ...   \n",
       "  2495      INLAND\n",
       "  2496      INLAND\n",
       "  2497      INLAND\n",
       "  2498      INLAND\n",
       "  2499      INLAND\n",
       "  Name: ocean_proximity, Length: 2500, dtype: object},\n",
       " 0       452600\n",
       " 1       358500\n",
       " 2       352100\n",
       " 3       341300\n",
       " 4       342200\n",
       "          ...  \n",
       " 2495     85000\n",
       " 2496     65600\n",
       " 2497     72200\n",
       " 2498     69600\n",
       " 2499     94300\n",
       " Name: median_house_value, Length: 2500, dtype: int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df1 = housing_df.copy()\n",
    "print(\"dataframe type :\" +str(type(housing_df1)))\n",
    "l1 = housing_df1.pop('median_house_value')\n",
    "#dict(l1)\n",
    "(dict(housing_df1),l1)\n",
    "#dict(housing_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    \n",
    "   # TODO 1a -- Your code here\n",
    "    labels = dataframe.pop('median_house_value')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we initialize the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_ds = df_to_dataset(train)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qRLGSMDzM-dl"
   },
   "source": [
    "Now that we have created the input pipeline, let's call it to see the format of the data it returns. We have used a small batch size to keep the output readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "colab_type": "code",
    "id": "CSBo3dUVNFc9",
    "outputId": "d1be2646-b1e5-4110-dbba-5bc49d9b30f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch type:  <class 'dict'>\n",
      "label_batch type:  <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "feature list:  ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'ocean_proximity']\n",
      "batch of households:  tf.Tensor(\n",
      "[ 182  448  694  351  278  422  373  817  677  481  698  432 1115  369\n",
      "  640  900  366  396  420  168  530  460  281  734  292  386  267  350\n",
      "  555  455  228  354], shape=(32,), dtype=int64)\n",
      "batch of ocean_proximity:  tf.Tensor(\n",
      "[b'INLAND' b'NEAR BAY' b'NEAR BAY' b'<1H OCEAN' b'INLAND' b'NEAR BAY'\n",
      " b'NEAR BAY' b'NEAR BAY' b'NEAR BAY' b'INLAND' b'INLAND' b'NEAR BAY'\n",
      " b'INLAND' b'NEAR BAY' b'INLAND' b'INLAND' b'NEAR BAY' b'INLAND' b'INLAND'\n",
      " b'INLAND' b'NEAR OCEAN' b'NEAR BAY' b'INLAND' b'NEAR BAY' b'NEAR BAY'\n",
      " b'INLAND' b'NEAR BAY' b'NEAR BAY' b'NEAR BAY' b'INLAND' b'NEAR BAY'\n",
      " b'NEAR BAY'], shape=(32,), dtype=string)\n",
      "batch of target:  tf.Tensor(\n",
      "[ 66000 368600 210200 275000  52000 182800 355600 256000 169300  49400\n",
      " 210100  86100  84500 165500 293200 176900 212600  75800  87100  88300\n",
      "  69500  97500  62800 331600 183300 167500 134500 211300 389500  87300\n",
      " 127000  98700], shape=(32,), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 20:56:45.668472: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# TODO 1b -- Your code here\n",
    "for feature_batch,label_batch in train_ds.take(1):\n",
    "    print(\"feature_batch type: \", type(feature_batch))\n",
    "    print(\"label_batch type: \", type(label_batch))\n",
    "    print(\"feature list: \", list(feature_batch.keys()))\n",
    "    print(\"batch of households: \", feature_batch['households'])\n",
    "    print(\"batch of ocean_proximity: \", feature_batch['ocean_proximity'])\n",
    "    print(\"batch of target: \", label_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OT5N6Se-NQsC"
   },
   "source": [
    "We can see that the dataset returns a dictionary of column names (from the dataframe) that map to column values from rows in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YEGEAqaziwfC"
   },
   "source": [
    "#### Numeric columns\n",
    "The output of a feature column becomes the input to the model. A numeric is the simplest type of column. It is used to represent real valued features. When using this column, your model will receive the column value from the dataframe unchanged.\n",
    "\n",
    "In the California housing prices dataset, most columns from the dataframe are numeric.  Let' create a variable called **numeric_cols** to hold only the numerical feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'latitude',\n",
       " 'housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'median_income',\n",
       " 'median_house_value',\n",
       " 'ocean_proximity']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO 1c -- Your code here\n",
    "#housing_df.info()\n",
    "numeric_cols=list(housing_df.columns)\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EwMEcH_52JT8"
   },
   "source": [
    "#### Scaler function\n",
    "It is very important for numerical variables to get scaled before they are \"fed\" into the neural network. Here we use min-max scaling. Here we are creating a function named 'get_scal' which takes a list of numerical features and returns a 'minmax' function, which will be used in tf.feature_column.numeric_column() as normalizer_fn in parameters. 'Minmax' function itself takes a 'numerical' number from a particular feature and return scaled value of that number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ig1k5ovWBnN8"
   },
   "source": [
    "Next, we scale the numerical feature columns that we assigned to the variable \"numeric cols\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar def get_scal(feature):\n",
    "# TODO 1d -- Your code here\n",
    "def get_scal(feature):\n",
    "    def minmax(x):\n",
    "        mini=train[feature].min()\n",
    "        maxi=train[feature].max()\n",
    "        return (x-mini)/(maxi-mini)\n",
    "    return minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y8IUfcuVaS_g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_4569/3254650526.py:4: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    }
   ],
   "source": [
    "# TODO 1e -- Your code here\n",
    "feature_columns = []\n",
    "for header in numeric_cols:\n",
    "    feature_columns.append(fc.numeric_column(header, normalizer_fn = get_scal(header)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8v9XoD7WCKRM"
   },
   "source": [
    "Next, we should validate the total number of feature columns.  Compare this number to the number of numeric features you input earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4jgPFThi50sS",
    "outputId": "23ede6f5-a62a-4767-b3a6-fe8a3b89a212"
   },
   "outputs": [],
   "source": [
    "print('Total number of feature coLumns: ', len(feature_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ug3hB8Sl0jO"
   },
   "source": [
    "### Using the Keras Sequential Model\n",
    "\n",
    "Next, we will run this cell to compile and fit the Keras Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_YJPPb3xTPeZ",
    "outputId": "2d445722-1d43-4a27-a6c0-c6ce813ab450"
   },
   "outputs": [],
   "source": [
    "# Model create\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns, dtype='float64')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(12, input_dim=8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(1, activation='linear',  name='median_house_value')\n",
    "])\n",
    "\n",
    "# Model compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "# Model Fit\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we show loss as  Mean Square Error (MSE).  Remember that MSE is the most commonly used regression loss function. MSE is the sum of squared distances between our target variable (e.g. housing median age) and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "vo7hhkPqm6Jx",
    "outputId": "938907f6-b6c8-497c-a8f6-0f1cdbf336c9"
   },
   "outputs": [],
   "source": [
    "loss, mse = model.evaluate(train_ds)\n",
    "print(\"Mean Squared Error\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "252EPxGp7-FJ"
   },
   "source": [
    "#### Visualize the model loss curve\n",
    "\n",
    "Next, we will use matplotlib to draw the model's loss curves for training and validation.  A line plot is also created showing the mean squared error loss over the training epochs for both the train (blue) and test (orange) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(history, metrics):\n",
    "    nrows = 1\n",
    "    ncols = 2\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "    for idx, key in enumerate(metrics):  \n",
    "        ax = fig.add_subplot(nrows, ncols, idx+1)\n",
    "        plt.plot(history.history[key])\n",
    "        plt.plot(history.history['val_{}'.format(key)])\n",
    "        plt.title('model {}'.format(key))\n",
    "        plt.ylabel(key)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left');  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(history, ['loss', 'mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqkozY268xi7"
   },
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uf4TyVJ_Dzxe"
   },
   "source": [
    "Next, we read in the test.csv file and validate that there are no null values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can use .describe() to see some summary statistics for the numeric fields in our dataframe.  The count shows 500.000000 for all feature columns. Thus, there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "b4C4BmhV8ch9",
    "outputId": "82bcc9d3-4432-4068-ab82-6a6abbe4a024"
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/housing-test.csv')\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nY2Yrt8fC7RW"
   },
   "source": [
    "Now that we have created an input pipeline using tf.data and compiled a Keras Sequential Model, we now create the input function for the test data and to initialize the test_predict variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rMdDeGDCwpT"
   },
   "outputs": [],
   "source": [
    "# TODO 1f -- Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = test_input_fn(dict(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5SkINtbDIdr"
   },
   "source": [
    "#### Prediction:  Linear Regression\n",
    "\n",
    "Before we begin to feature engineer our feature columns, we should predict the median house value.  By predicting the median house value now, we can then compare it with the median house value after feature engineering.\n",
    "\n",
    "To predict with Keras, you simply call [model.predict()](https://keras.io/models/model/#predict) and pass in the housing features you want to predict the median_house_value for. Note:  We are predicting the model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uNc6TSoJDL7-"
   },
   "outputs": [],
   "source": [
    "predicted_median_house_value = model.predict(test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFXK1SKPDYgD"
   },
   "source": [
    "Next, we run two predictions in separate cells - one where ocean_proximity=INLAND and one where ocean_proximity= NEAR OCEAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xepss0vhoHge",
    "outputId": "46842a26-eacd-4801-857b-18c6a8f2005c"
   },
   "outputs": [],
   "source": [
    "# Ocean_proximity is INLAND\n",
    "model.predict({\n",
    "    'longitude': tf.convert_to_tensor([-121.86]),\n",
    "    'latitude': tf.convert_to_tensor([39.78]),\n",
    "    'housing_median_age': tf.convert_to_tensor([12.0]),\n",
    "    'total_rooms': tf.convert_to_tensor([7653.0]),\n",
    "    'total_bedrooms': tf.convert_to_tensor([1578.0]),\n",
    "    'population': tf.convert_to_tensor([3628.0]),\n",
    "    'households': tf.convert_to_tensor([1494.0]),\n",
    "    'median_income': tf.convert_to_tensor([3.0905]),\n",
    "    'ocean_proximity': tf.convert_to_tensor(['INLAND'])\n",
    "}, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qPssm8p4EZHh",
    "outputId": "2a55d427-7857-401c-f60d-edbb36be19ec"
   },
   "outputs": [],
   "source": [
    "# Ocean_proximity is NEAR OCEAN\n",
    "model.predict({\n",
    "    'longitude': tf.convert_to_tensor([-122.43]),\n",
    "    'latitude': tf.convert_to_tensor([37.63]),\n",
    "    'housing_median_age': tf.convert_to_tensor([34.0]),\n",
    "    'total_rooms': tf.convert_to_tensor([4135.0]),\n",
    "    'total_bedrooms': tf.convert_to_tensor([687.0]),\n",
    "    'population': tf.convert_to_tensor([2154.0]),\n",
    "    'households': tf.convert_to_tensor([742.0]),\n",
    "    'median_income': tf.convert_to_tensor([4.9732]),\n",
    "    'ocean_proximity': tf.convert_to_tensor(['NEAR OCEAN'])\n",
    "}, steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Txl-MRuLFE_8"
   },
   "source": [
    "The arrays returns a predicted value.  What do these numbers mean?  Let's compare this value to the test set.  \n",
    "\n",
    "Go to the test.csv you read in a few cells up.  Locate the first line and find the median_house_value - which should be 249,000 dollars near the ocean. What value did your model predicted for the median_house_value? Was it a solid model performance? Let's see if we can improve this a bit with feature engineering!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task 2: Engineer features to create categorical and numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "78F1XH1Qwvbt"
   },
   "source": [
    "Now we create a cell that indicates which features will be used in the model.  \n",
    "Note:  Be sure to bucketize 'housing_median_age' and ensure that 'ocean_proximity' is one-hot encoded.  And, don't forget your numeric values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZxSatLUxUmvI"
   },
   "outputs": [],
   "source": [
    "# TODO 2a -- Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5HbypkYHxxwt"
   },
   "source": [
    "Next, we scale the numerical, bucktized, and categorical feature columns that we assigned to the variables in the preceding cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExX5Akz0UnE-"
   },
   "outputs": [],
   "source": [
    "# Scalar def get_scal(feature):\n",
    "def get_scal(feature):\n",
    "    def minmax(x):\n",
    "        mini = train[feature].min()\n",
    "        maxi = train[feature].max()\n",
    "        return (x - mini)/(maxi-mini)\n",
    "        return(minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wzqcddUQUnKn"
   },
   "outputs": [],
   "source": [
    "# All numerical features - scaling\n",
    "feature_columns = []\n",
    "for header in numeric_cols:\n",
    "    scal_input_fn = get_scal(header)\n",
    "    feature_columns.append(fc.numeric_column(header,\n",
    "                                             normalizer_fn=scal_input_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYUpUZvgwrPe"
   },
   "source": [
    "### Categorical Feature\n",
    "In this dataset, 'ocean_proximity' is represented as a string.  We cannot feed strings directly to a model. Instead, we must first map them to numeric values. The categorical vocabulary columns provide a way to represent strings as a one-hot vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZnlnFZkyEbe"
   },
   "source": [
    "Next, we create a categorical feature using 'ocean_proximity'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Cf6SoFTUnc6"
   },
   "outputs": [],
   "source": [
    "# TODO 2b -- Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnGyWaijzShj"
   },
   "source": [
    "### Bucketized Feature\n",
    "\n",
    "Often, you don't want to feed a number directly into the model, but instead split its value into different categories based on numerical ranges. Consider our raw data that represents a homes' age. Instead of representing the house age as a numeric column, we could split the home age into several buckets using a [bucketized column](https://www.tensorflow.org/api_docs/python/tf/feature_column/bucketized_column). Notice the one-hot values below describe which age range each row matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZRlFyP7fOw-"
   },
   "source": [
    "Next we create a bucketized column using 'housing_median_age'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xB-yiVLmUnXp"
   },
   "outputs": [],
   "source": [
    "# TODO 2c -- Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ri4_wssOg943"
   },
   "source": [
    "### Feature Cross\n",
    "\n",
    "Combining features into a single feature, better known as [feature crosses](https://developers.google.com/machine-learning/glossary/#feature_cross), enables a model to learn separate weights for each combination of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6HHJl3J0j0T"
   },
   "source": [
    "Next, we create a feature cross of 'housing_median_age' and 'ocean_proximity'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JVLnG0WbUnkl"
   },
   "outputs": [],
   "source": [
    "# TODO 2d -- Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiz6HCWg1CXO"
   },
   "source": [
    "Next, we should validate the total number of feature columns.  Compare this number to the number of numeric features you input earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6P3Ewc3_Unsv",
    "outputId": "42c1c4a6-89f8-4685-b2d0-e76a90cdf9ee"
   },
   "outputs": [],
   "source": [
    "print('Total number of feature columns: ', len(feature_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lNr00mP41sJp"
   },
   "source": [
    "Next, we will run this cell to compile and fit the Keras Sequential model.  This is the same model we ran earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4Dwal3oxUoCe",
    "outputId": "1ae08747-7dbe-47a5-b3e7-87581e460b1b"
   },
   "outputs": [],
   "source": [
    "# Model create\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns,\n",
    "                                              dtype='float64')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(12, input_dim=8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(1, activation='linear',  name='median_house_value')\n",
    "])\n",
    "\n",
    "# Model compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "# Model Fit\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LdUQszM16Oj"
   },
   "source": [
    "Next, we show loss and mean squared error then plot the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ZtFSpkd9UoAW",
    "outputId": "bac4836e-c4f1-4b29-876d-91fe1b51a5a7"
   },
   "outputs": [],
   "source": [
    "loss, mse = model.evaluate(train_ds)\n",
    "print(\"Mean Squared Error\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "O8kWMa6xUn-M",
    "outputId": "05ed9323-1102-4245-a40b-88543f11b0f3"
   },
   "outputs": [],
   "source": [
    "plot_curves(history, ['loss', 'mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4tWwOQt2e-P"
   },
   "source": [
    "Next we create a prediction model.  Note:  You may use the same values from the previous prediciton.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2e -- Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rcbdA3arXkej"
   },
   "source": [
    "### Analysis \n",
    "\n",
    "The array returns a predicted value.  Compare this value to the test set you ran earlier. Your predicted value may be a bit better.\n",
    "\n",
    "Now that you have your \"feature engineering template\" setup, you can experiment by creating additional features.  For example, you can create derived features, such as households per population, and see how they impact the model.  You can also experiment with replacing the features you used to create the feature cross.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2022 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Basic Feature Engineering in Keras.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
